{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f09c369d-8fdd-41f0-b0af-ba7118fa086d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/irina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c6117f9-e177-4a5f-b70f-46aaf99a67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymystem3 import Mystem\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1e69a2e-ffa3-4941-b4fa-c28720cf5e30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mystem = Mystem()\n",
    "swords = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ea1b82b-dd17-4ac6-a36b-b3ce9dcf2bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file newssmartlab_messages.json in work\n",
      "message ready\n",
      "1 из 25 готов\n",
      "file rt_russian_messages.json in work\n",
      "message ready\n",
      "2 из 25 готов\n",
      "file SberInvestments_messages.json in work\n",
      "message ready\n",
      "3 из 25 готов\n",
      "file Stock_News100_messages.json in work\n",
      "message ready\n",
      "4 из 25 готов\n",
      "file frank_media_messages.json in work\n",
      "message ready\n",
      "5 из 25 готов\n",
      "file rian_ru_messages.json in work\n",
      "message ready\n",
      "6 из 25 готов\n",
      "file banki_economy_messages.json in work\n",
      "message ready\n",
      "7 из 25 готов\n",
      "file economylive_messages.json in work\n",
      "message ready\n",
      "8 из 25 готов\n",
      "file gazprom_messages.json in work\n",
      "message ready\n",
      "9 из 25 готов\n",
      "file investingcorp_messages.json in work\n",
      "message ready\n",
      "10 из 25 готов\n",
      "file tass_agency_messages.json in work\n",
      "message ready\n",
      "11 из 25 готов\n",
      "file rbc_news_messages.json in work\n",
      "message ready\n",
      "12 из 25 готов\n",
      "file nedvizhna24_messages.json in work\n",
      "message ready\n",
      "13 из 25 готов\n",
      "file gazpromneft_official_messages.json in work\n",
      "message ready\n",
      "14 из 25 готов\n",
      "file bankser_messages.json in work\n",
      "message ready\n",
      "15 из 25 готов\n",
      "file headlines_for_traders_messages.json in work\n",
      "message ready\n",
      "16 из 25 готов\n",
      "file econs_messages.json in work\n",
      "message ready\n",
      "17 из 25 готов\n",
      "file FatCat18_messages.json in work\n",
      "message ready\n",
      "18 из 25 готов\n",
      "file kommersant_messages.json in work\n",
      "message ready\n",
      "19 из 25 готов\n",
      "file markettwits_messages.json in work\n",
      "message ready\n",
      "20 из 25 готов\n",
      "file banksta_messages.json in work\n",
      "message ready\n",
      "21 из 25 готов\n",
      "file BIoomberg_messages.json in work\n",
      "message ready\n",
      "22 из 25 готов\n",
      "file forbesrussia_messages.json in work\n",
      "message ready\n",
      "23 из 25 готов\n",
      "file sosisochniyparserru_messages.json in work\n",
      "message ready\n",
      "24 из 25 готов\n",
      "file vedomosti_messages.json in work\n",
      "message ready\n",
      "25 из 25 готов\n"
     ]
    }
   ],
   "source": [
    "from text_preprocess import preprocess_tg\n",
    "files = os.listdir('Telegram_data')\n",
    "if '.ipynb_checkpoints' in files:\n",
    "    files.remove('.ipynb_checkpoints')\n",
    "c = 1\n",
    "\n",
    "for file in files:\n",
    "    print(f'file {file} in work')\n",
    "    warnings.filterwarnings('ignore')\n",
    "    df = preprocess_tg(f'/{file}', swords)  # Передаем swords\n",
    "    warnings.filterwarnings('default')\n",
    "    \n",
    "    if df is not None:  # Проверяем, что df не None\n",
    "        df.to_csv(f'Telegram_prep/{file[:-5]}.csv', index=False)  \n",
    "        print(f'{c} из {len(files)} готов')\n",
    "        c += 1\n",
    "    else:\n",
    "        print(f'Ошибка при обработке файла {file}. Результат: None.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9726c5b2-4c47-43a1-91b9-2feb6a59d403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обрабатывается файл rt_russian_messages.csv\n",
      "Обрабатывается файл econs_messages.csv\n",
      "Обрабатывается файл banki_economy_messages.csv\n",
      "Обрабатывается файл SberInvestments_messages.csv\n",
      "Обрабатывается файл Stock_News100_messages.csv\n",
      "Обрабатывается файл kommersant_messages.csv\n",
      "Обрабатывается файл headlines_for_traders_messages.csv\n",
      "Обрабатывается файл markettwits_messages.csv\n",
      "Обрабатывается файл forbesrussia_messages.csv\n",
      "Обрабатывается файл investingcorp_messages.csv\n",
      "Обрабатывается файл banksta_messages.csv\n",
      "Обрабатывается файл rian_ru_messages.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/irina/Desktop/Master_VKR/code/price_prediction_news/src/text_preprocess.py:165: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'Telegram_prep/{file}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обрабатывается файл economylive_messages.csv\n",
      "Обрабатывается файл sosisochniyparserru_messages.csv\n",
      "Обрабатывается файл newssmartlab_messages.csv\n",
      "Обрабатывается файл gazpromneft_official_messages.csv\n",
      "Обрабатывается файл tass_agency_messages.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/irina/Desktop/Master_VKR/code/price_prediction_news/src/text_preprocess.py:165: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'Telegram_prep/{file}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обрабатывается файл BIoomberg_messages.csv\n",
      "Обрабатывается файл vedomosti_messages.csv\n",
      "Обрабатывается файл nedvizhna24_messages.csv\n",
      "Обрабатывается файл rbc_news_messages.csv\n",
      "Обрабатывается файл gazprom_messages.csv\n",
      "Обрабатывается файл frank_media_messages.csv\n",
      "Обрабатывается файл bankser_messages.csv\n",
      "Обрабатывается файл FatCat18_messages.csv\n"
     ]
    }
   ],
   "source": [
    "from text_preprocess import telegram_to_standard_date\n",
    "telegram_to_standard_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0756ee33-b2bc-43a7-88a5-34f3d70eb2f1",
   "metadata": {},
   "source": [
    "### Формирование датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6d1d204-2274-4342-9dae-a763dba4e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = {\n",
    "    'VTBR': 'vtb', \n",
    "   'GAZP' : 'gazprom', \n",
    "    'SBER': 'sberbank',\n",
    "    'NVTK': 'novatek',\n",
    "    'ROSN': 'rosneft'}\n",
    "data_dir = 'finam_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25b1ceb7-aaef-43f6-899f-99ba48c8a77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл SBER_20200101_20250331.csv успешно создан.\n",
      "Файл GAZP_20200101_20250331.csv успешно создан.\n",
      "Файл VTBR_20200101_20250331.csv успешно создан.\n",
      "Файл NVTK_20200101_20250331.csv успешно создан.\n",
      "Файл ROSN_20200101_20250331.csv успешно создан.\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'Stock_data'\n",
    "# Список компаний\n",
    "compani = ['SBER', 'GAZP', 'VTBR', 'NVTK', 'ROSN'] \n",
    "\n",
    "# Обработка каждой компании\n",
    "for company_name in compani:\n",
    "    # Список файлов для текущей компании\n",
    "    files = [f for f in os.listdir(data_dir) if f.startswith(company_name)]\n",
    "\n",
    "    # Объединение данных\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    for file in files:\n",
    "        file_path = os.path.join(data_dir, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        data = pd.concat([data, df], ignore_index=True)\n",
    "\n",
    "    # Сохранение результата\n",
    "    output_file = f'{company_name}_20200101_20250331.csv'\n",
    "    output_path = os.path.join(output_dir, output_file)\n",
    "    data.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f'Файл {output_file} успешно создан.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1323723f-eff5-4f9b-80b8-1d2793c2f085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBER готов\n",
      "GAZP готов\n",
      "VTBR готов\n",
      "NVTK готов\n",
      "ROSN готов\n"
     ]
    }
   ],
   "source": [
    "#Собираем данные дат в один файл\n",
    "folders = os.listdir('Stock_data')\n",
    "folders = [f for f in folders if f[0] != '.']\n",
    "for folder in folders:\n",
    "    for company in companies:\n",
    "        files = os.listdir(f'Stock_data/{folder}')\n",
    "        files = [f for f in files if company in f and '0101' in f]\n",
    "        data = pd.DataFrame()\n",
    "        for file in files:\n",
    "            try:\n",
    "                tmp = pd.read_csv(f'Stock_data/{folder}/{file}', sep=';')[['<DATE>', '<TIME>', '<CLOSE>']]\n",
    "                if folder == '1 день':\n",
    "                    time = tmp['<DATE>'].astype(str)\n",
    "                    tmp['timestamp'] = pd.to_datetime(time, format='%y%m%d')\n",
    "                    tmp.sort_values('timestamp', inplace=True)\n",
    "                elif folder == '1 час':\n",
    "                    time = tmp['<DATE>'].astype(str) + tmp['<TIME>'].astype(str).map(lambda x: '235000' if x == '0' else x)\n",
    "                    tmp['timestamp'] = pd.to_datetime(time, format='%y%m%d%H%M%S')\n",
    "                    tmp.sort_values('timestamp', inplace=True)\n",
    "                else:\n",
    "                    time = tmp['<DATE>'].astype(str) + tmp['<TIME>'].astype(str).map(lambda x: '235000' if x == '0' else x)\n",
    "                    tmp['timestamp'] = pd.to_datetime(time, format='%y%m%d%H%M%S')\n",
    "                    tmp.sort_values('timestamp', inplace=True)\n",
    "\n",
    "                tmp.drop(columns=['<DATE>', '<TIME>'], inplace=True)\n",
    "                tmp.columns = ['close', 'timestamp']\n",
    "                tmp.sort_values('timestamp', inplace=True)\n",
    "                data = pd.concat([data, tmp], axis=0)\n",
    "            except Exception as ex:\n",
    "                print(folder)\n",
    "                print(file)\n",
    "                print(ex)\n",
    "        data.to_csv(f'Stock_data/{folder}/{company}.csv', index=False)\n",
    "        print(f'{company} готов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1976bb48-b54b-48b3-b305-1c305c9947cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/irina/Desktop/Master_VKR/code/price_prediction_news/src/text_preprocess.py:104: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'Telegram_prep/{file}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/irina/Desktop/Master_VKR/code/price_prediction_news/src/text_preprocess.py:104: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'Telegram_prep/{file}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n",
      "VTBR готов\n",
      "GAZP готов\n",
      "SBER готов\n",
      "NVTK готов\n",
      "ROSN готов\n"
     ]
    }
   ],
   "source": [
    "from text_preprocess import add_target_tg\n",
    "add_target_tg(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bd6f700-b81e-4214-bfff-b24f8e4b9147",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Stock_data/1 мин./VTBR.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#??? нужны ли бинанрные даные\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtext_preprocess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_target_bin_tg\n\u001b[0;32m----> 3\u001b[0m add_target_bin_tg(companies)\n",
      "File \u001b[0;32m~/Desktop/Master_VKR/code/price_prediction_news/src/text_preprocess.py:142\u001b[0m, in \u001b[0;36madd_target_bin_tg\u001b[0;34m(companies)\u001b[0m\n\u001b[1;32m    139\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m com \u001b[38;5;129;01min\u001b[39;00m comp:\n\u001b[0;32m--> 142\u001b[0m     price \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Stock_data/1 мин./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcom\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    143\u001b[0m     price[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(price[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    144\u001b[0m     price\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Stock_data/1 мин./VTBR.csv'"
     ]
    }
   ],
   "source": [
    "#??? нужны ли бинанрные даные\n",
    "from text_preprocess import add_target_bin_tg\n",
    "add_target_bin_tg(companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c40736-5beb-40a9-8b8b-303ba1ef6159",
   "metadata": {},
   "source": [
    "Принадлежность новости к компании"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18e5a106-7376-48c1-9c42-de1c0eed0640",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_regex = {\n",
    "    'VTBR': ['втб', 'почта банк', 'транскредитбанк', 'vtb', 'банк москвы', 'мультикарта', 'галс девелопмент',\n",
    "            'бм банк', 'согаз'],\n",
    "    'GAZP': ['газпром', 'gazp', 'северный поток', 'сила сибири', 'голубой поток', 'ямал европа',\n",
    "             'ямал европа', 'ухта торжок', 'gazprom'], \n",
    "    'SBER': ['/^сбер$/', 'сбербанк', 'sber', 'сбермегамаркет', 'сбермаркет', 'сберздоровье'],\n",
    "    'NVTK': ['новатэк', 'nvtk', 'novatek', 'ямал спг', 'арктикгаз', 'нортгаз', 'арктик спг', 'транснефтегаз'],\n",
    "    'ROSN': ['роснефть', 'rosn', 'самаранефтегаз', 'rosneft', 'роснефти']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d85110f-346b-4b6a-8b9f-f95f3f187559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "markettwits.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/irina/Desktop/Master_VKR/code/price_prediction_news/src/text_preprocess.py:58: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'Telegram_prep/{file}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rian_ru.csv done\n",
      "Stock_News100.csv done\n",
      "bankser.csv done\n",
      "rt_russian_messages.csv done\n",
      "econs_messages.csv done\n",
      "banki_economy_messages.csv done\n",
      "economylive.csv done\n",
      "tass_agency.csv done\n",
      "SberInvestments_messages.csv done\n",
      "FatCat18.csv done\n",
      "Stock_News100_messages.csv done\n",
      "kommersant_messages.csv done\n",
      "rt_russian.csv done\n",
      "banki_economy.csv done\n",
      "forbesrussia.csv done\n",
      "kommersant.csv done\n",
      "headlines_for_traders_messages.csv done\n",
      "nedvizhna24.csv done\n",
      "markettwits_messages.csv done\n",
      "forbesrussia_messages.csv done\n",
      "investingcorp_messages.csv done\n",
      "BIoomberg.csv done\n",
      "gazpromneft_official.csv done\n",
      "banksta_messages.csv done\n",
      "SberInvestments.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/irina/Desktop/Master_VKR/code/price_prediction_news/src/text_preprocess.py:58: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'Telegram_prep/{file}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rian_ru_messages.csv done\n",
      "economylive_messages.csv done\n",
      "newssmartlab.csv done\n",
      "sosisochniyparserru_messages.csv done\n",
      "newssmartlab_messages.csv done\n",
      "gazpromneft_official_messages.csv done\n",
      "investingcorp.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/irina/Desktop/Master_VKR/code/price_prediction_news/src/text_preprocess.py:58: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'Telegram_prep/{file}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tass_agency_messages.csv done\n",
      "gazprom.csv done\n",
      "sosisochniyparserru.csv done\n",
      "vedomosti.csv done\n",
      "banksta.csv done\n",
      "BIoomberg_messages.csv done\n",
      "econs.csv done\n",
      "vedomosti_messages.csv done\n",
      "nedvizhna24_messages.csv done\n",
      "rbc_news_messages.csv done\n",
      "gazprom_messages.csv done\n",
      "rbc_news.csv done\n",
      "frank_media_messages.csv done\n",
      "bankser_messages.csv done\n",
      "headlines_for_traders.csv done\n",
      "FatCat18_messages.csv done\n",
      "frank_media.csv done\n"
     ]
    }
   ],
   "source": [
    "from text_preprocess import add_company_tg\n",
    "add_company_tg(for_regex, companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "469a01e8-fa5b-4121-b0c1-7252b9913c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_root = 'Telegram_prep'\n",
    "import os\n",
    "folders = os.listdir(tg_root)\n",
    "folders = [f for f in folders if 'csv' not in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d118c95b-7c22-42ed-b2a5-bd1aca7526de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Телеграмм\u001b[39;00m\n\u001b[1;32m      2\u001b[0m agg_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.ipynb_checkpoints\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m      4\u001b[0m         files\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.ipynb_checkpoints\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m folders:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "### Телеграмм\n",
    "agg_df = pd.DataFrame()\n",
    "if '.ipynb_checkpoints' in files:\n",
    "        files.remove('.ipynb_checkpoints')\n",
    "for folder in folders:\n",
    "    files = [\n",
    "        folder + el + '.parquet' for el in ['_data', '_abs_values', '_rel_values', '_company']\n",
    "    ]\n",
    "    tmp_agg_df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        tmp = pd.read_parquet(tg_root + '/' + folder + '/' + file)\n",
    "        tmp_agg_df = pd.concat([tmp_agg_df, tmp], axis=1)\n",
    "    tmp_agg_df['source'] = folder\n",
    "    agg_df = pd.concat([agg_df, tmp_agg_df])\n",
    "    print(folder)\n",
    "agg_df.to_parquet('Data/tg.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6fa5a9-39e4-4c33-be25-18655501f6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
